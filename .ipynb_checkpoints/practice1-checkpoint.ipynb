{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2287f5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f8a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "x_train_path = '/Users/minki/prepare_dataq_test/dataset/X_train.csv'\n",
    "y_train_path = '/Users/minki/prepare_dataq_test/dataset/y_train.csv'\n",
    "\n",
    "x_test_path = '/Users/minki/prepare_dataq_test/dataset/X_test.csv'\n",
    "\n",
    "x_train = pd.read_csv(x_train_path, encoding = 'cp949')\n",
    "y_train = pd.read_csv(y_train_path, encoding = 'cp949')\n",
    "\n",
    "x_test = pd.read_csv(x_test_path, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dba5619",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-34a5b5f4c27e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-34a5b5f4c27e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    x_train.iloc[:, [0, 3:8]].head()\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x_train.iloc[:, [0, ]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24ee0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2482 entries, 0 to 2481\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   cust_id  2482 non-null   int64  \n",
      " 1   총구매액     2482 non-null   int64  \n",
      " 2   최대구매액    2482 non-null   int64  \n",
      " 3   환불금액     871 non-null    float64\n",
      " 4   주구매상품    2482 non-null   object \n",
      " 5   주구매지점    2482 non-null   object \n",
      " 6   내점일수     2482 non-null   int64  \n",
      " 7   내점당구매건수  2482 non-null   float64\n",
      " 8   주말방문비율   2482 non-null   float64\n",
      " 9   구매주기     2482 non-null   int64  \n",
      "dtypes: float64(3), int64(5), object(2)\n",
      "memory usage: 194.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# see data info\n",
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90530208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cust_id       0\n",
      "총구매액          0\n",
      "최대구매액         0\n",
      "환불금액       2295\n",
      "주구매상품         0\n",
      "주구매지점         0\n",
      "내점일수          0\n",
      "내점당구매건수       0\n",
      "주말방문비율        0\n",
      "구매주기          0\n",
      "dtype: int64\n",
      "======================\n",
      "cust_id       0\n",
      "총구매액          0\n",
      "최대구매액         0\n",
      "환불금액       1611\n",
      "주구매상품         0\n",
      "주구매지점         0\n",
      "내점일수          0\n",
      "내점당구매건수       0\n",
      "주말방문비율        0\n",
      "구매주기          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# train과 test data의 null개수\n",
    "\n",
    "print(x_train.isnull().sum())\n",
    "print('======================')\n",
    "print(x_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9063dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na\n",
    "\n",
    "imputer = SimpleImputer(strategy = 'constant')\n",
    "imputer.fit(pd.DataFrame(x_train['환불금액']))\n",
    "x_train['환불금액'] = imputer.transform(pd.DataFrame(x_train['환불금액']))\n",
    "\n",
    "imputer.fit(pd.DataFrame(x_test['환불금액']))\n",
    "x_test['환불금액'] = imputer.transform(pd.DataFrame(x_test['환불금액']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac0e4a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "# 환불금액의 null값이 너무 많으므로 총구매액에서 환불금액을 뺀 값을 최종구매액으로 설정\n",
    "# 환불금액이 큰 경우가 있는데 이는 비율이 낮으므로 0으로 대체할 예정\n",
    "# x_test는 절대 삭제하면 안됨. 이거 삭제하면 나중에 y_test와 차원 길이가 달라짐\n",
    "print(len(x_train)-(x_train['총구매액'] > x_train['환불금액']).sum())\n",
    "print(len(x_test)-(x_test['총구매액'] > x_test['환불금액']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b309131",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['최종구매액'] = x_train['총구매액'] - x_train['환불금액']\n",
    "x_test['최종구매액'] = x_test['총구매액'] - x_test['환불금액']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acc8af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 원본 복사 및\n",
    "# 최종구매액이 0보다 작은 행 삭제\n",
    "\n",
    "x_train_copy = x_train.copy()\n",
    "x_test_copy = x_test.copy()\n",
    "\n",
    "x_train_copy['최종구매액'] = x_train_copy['최종구매액'].apply(lambda x: x if(x>0) else 0)\n",
    "x_test_copy['최종구매액'] = x_test_copy['최종구매액'].apply(lambda x: x if(x>0) else 0)\n",
    "\n",
    "# 총구매액, 환불금액 drop\n",
    "x_train_copy = x_train_copy.drop(['총구매액', '환불금액'], axis = 1)\n",
    "x_test_copy = x_test_copy.drop(['총구매액', '환불금액'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23f39189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate cust_id and drop cust_id\n",
    "\n",
    "x_train_cust_id = x_train['cust_id']\n",
    "x_train = x_train.iloc[:, 1:]\n",
    "x_test_cust_id = x_test['cust_id']\n",
    "x_test = x_test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bbf81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주구매상품과 주구매지점 Encoding\n",
    "\n",
    "x_train_copy.loc[:, ['주구매상품', '주구매지점']] = x_train_copy.loc[:, ['주구매상품', '주구매지점']].apply(LabelEncoder().fit_transform)\n",
    "x_test_copy.loc[:, ['주구매상품', '주구매지점']] = x_test_copy.loc[:, ['주구매상품', '주구매지점']].apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47e058fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대구매액, 내점일수, 내점당구매건수, 주말방문비율, 구매주기, 최종구매액\n",
    "# 위의 지표들은 scale이 다 다르므로 MinMaxScaler를 적용해서 변환\n",
    "# 모든 지표가 다 음수가 될 수 없기에 StandardScaler대신 적용\n",
    "\n",
    "minMaxScaler_train = MinMaxScaler()\n",
    "minMaxScaler_test = MinMaxScaler()\n",
    "\n",
    "minMaxScaler_train.fit(x_train_copy.iloc[:, [0, 3, 4, 5, 6, 7]])\n",
    "minMaxScaler_test.fit(x_test_copy.iloc[:, [0, 3, 4, 5, 6, 7]])\n",
    "\n",
    "x_train_copy.iloc[:, [0, 3, 4, 5, 6, 7]] = minMaxScaler_train.transform(x_train_copy.iloc[:, [0, 3, 4, 5, 6, 7]])\n",
    "x_test_copy.iloc[:, [0, 3, 4, 5, 6, 7]] = minMaxScaler_test.transform(x_test_copy.iloc[:, [0, 3, 4, 5, 6, 7]])                                                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48fffef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train의 주구매상품 데이터 종류 : 42\n",
      "train의 주구매지점 데이터 종류 : 24\n",
      "test의 주구매상품 데이터 종류 : 41\n",
      "test의 주구매지점 데이터 종류 : 24\n"
     ]
    }
   ],
   "source": [
    "# 주구매상품과 주구매지점 개수 파악 후 출력\n",
    "\n",
    "kinds_train_product = len(x_train['주구매상품'].value_counts())\n",
    "kinds_train_site = len(x_train['주구매지점'].value_counts())\n",
    "\n",
    "kinds_test_product = len(x_test['주구매상품'].value_counts())\n",
    "kinds_test_site = len(x_test['주구매지점'].value_counts())\n",
    "\n",
    "print(f'train의 주구매상품 데이터 종류 : {kinds_train_product}')\n",
    "print(f'train의 주구매지점 데이터 종류 : {kinds_train_site}')\n",
    "\n",
    "print(f'test의 주구매상품 데이터 종류 : {kinds_test_product}')\n",
    "print(f'test의 주구매지점 데이터 종류 : {kinds_test_site}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a678098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 종류가 너무 많으므로 Clustering을 실시\n",
    "\n",
    "train_product_kmeans = KMeans(n_clusters = 3)\n",
    "cluster_train_product = x_train_copy.iloc[:, [0, 1, 3, 4, 5, 6, 7]]\n",
    "train_product_kmeans.fit(cluster_train_product)\n",
    "x_train_copy['product'] = train_product_kmeans.labels_\n",
    "\n",
    "test_product_kmeans = KMeans(n_clusters = 3)\n",
    "cluster_test_product = x_test_copy.iloc[:, [0, 1, 3, 4, 5, 6, 7]]\n",
    "test_product_kmeans.fit(cluster_test_product)\n",
    "x_test_copy['product'] = test_product_kmeans.labels_\n",
    "\n",
    "train_site_kmeans = KMeans(n_clusters = 3)\n",
    "cluster_train_site = x_train_copy.iloc[:, [0, 2, 3, 4, 5, 6, 7]]\n",
    "train_site_kmeans.fit(cluster_train_site)\n",
    "x_train_copy['site'] = train_site_kmeans.labels_\n",
    "\n",
    "test_site_kmeans = KMeans(n_clusters = 3)\n",
    "cluster_test_site = x_test_copy.iloc[:, [0, 2, 3, 4, 5, 6, 7]]\n",
    "test_site_kmeans.fit(cluster_test_site)\n",
    "x_test_copy['site'] = test_site_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4719742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주구매상품과 주구매지점 열 삭제\n",
    "x_train_copy = x_train_copy.drop(['주구매상품', '주구매지점'], axis = 1)\n",
    "x_test_copy = x_test_copy.drop(['주구매상품', '주구매지점'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b377685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minki/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:56:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:56:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8655963305944309\n"
     ]
    }
   ],
   "source": [
    "# xgboost를 통한 Classifier 적용\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_estimator = 400, learning_rate = 0.1, max_depth = 5)\n",
    "xgb_model.fit(x_train_copy, y_train.iloc[:, 1])\n",
    "\n",
    "# roc 점수 도출\n",
    "predict_train = pd.DataFrame(xgb_model.predict_proba(x_train_copy))\n",
    "roc_score = roc_auc_score(y_train.iloc[:, 1], predict_train.iloc[:, 1])\n",
    "print(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "18e0c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 도출\n",
    "predict_test = xgb_model.predict_proba(x_test_copy)\n",
    "res_man = pd.DataFrame(predict_test).iloc[:, 1]\n",
    "res_man = pd.DataFrame(res_man)\n",
    "\n",
    "res = pd.concat([pd.DataFrame(x_test_cust_id), res_man], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d13a5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('/Users/minki/prepare_dataq_test/res/100000.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36de303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cebe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import xgboost as xgb\n",
    "\n",
    "x_train_path = 'data/X_train.csv'\n",
    "x_test_path = 'data/X_test.csv'\n",
    "y_train_path = 'data/y_train.csv'\n",
    "\n",
    "x_train = pd.read_csv(x_train_path)\n",
    "y_train = pd.read_csv(y_train_path)\n",
    "x_test = pd.read_csv(x_test_path)\n",
    "\n",
    "# cust_id의 형태 변환\n",
    "x_train['cust_id'] = x_train['cust_id'].astype('object')\n",
    "x_test['cust_id'] = x_test['cust_id'].astype('object')\n",
    "\n",
    "# cust_id를 따로 저장 및 기존 데이터셋에서 분리\n",
    "\n",
    "x_train_copy = x_train.copy()\n",
    "x_test_copy = x_test.copy()\n",
    "\n",
    "x_train_custID = x_train['cust_id']\n",
    "x_test_custID = x_test['cust_id']\n",
    "\n",
    "x_train = x_train.drop(['cust_id'], axis = 1)\n",
    "x_test = x_test.drop(['cust_id'], axis = 1)\n",
    "\n",
    "# 환불금액에서 null값이 보이므로 이를 0값으로 채움\n",
    "\n",
    "# 환불금액의 null 값을 계산해보자\n",
    "\n",
    "x_train.isnull().sum()['환불금액']\n",
    "x_test.isnull().sum()['환불금액']\n",
    "\n",
    "# null값을 0으로 채우자\n",
    "\n",
    "simpleImputer_train = SimpleImputer(strategy = 'constant')\n",
    "simpleImputer_test = SimpleImputer(strategy = 'constant')\n",
    "\n",
    "simpleImputer_train.fit(pd.DataFrame(x_train['환불금액']))\n",
    "simpleImputer_test.fit(pd.DataFrame(x_test['환불금액']))\n",
    "\n",
    "x_train['환불금액'] = simpleImputer_train.transform(pd.DataFrame(x_train['환불금액']))\n",
    "x_test['환불금액'] = simpleImputer_test.transform(pd.DataFrame(x_test['환불금액']))\n",
    "\n",
    "# null값이 너무 많은 관계로 삭제할 수 없고 또 그렇다고 이 데이터를 그대로 이용하기에도 무리가 있다.\n",
    "# 따라서 총구매액 - 환불금액 해서 최종구매액 행을 신설하자.\n",
    "\n",
    "x_train['최종구매액'] = x_train['총구매액'] - x_train['환불금액'] \n",
    "x_test['최종구매액'] = x_test['총구매액'] - x_test['환불금액']\n",
    "\n",
    "x_train['최종구매액'] = x_train['최종구매액'].apply(lambda x: x if(x > 0) else 0)\n",
    "x_test['최종구매액'] = x_test['최종구매액'].apply(lambda x: x if(x > 0) else 0)\n",
    "\n",
    "# 총구매액과 환불금액을 날리자\n",
    "\n",
    "x_train = x_train.drop(['총구매액', '환불금액'], axis = 1)\n",
    "x_test = x_test.drop(['총구매액', '환불금액'], axis = 1)\n",
    "\n",
    "# 주구매상품과 주구매지점이 String 형식이므로 encoding이 필요하다.\n",
    "\n",
    "x_train.loc[:, ['주구매상품', '주구매지점']] = x_train.loc[:, ['주구매상품', '주구매지점']].apply(LabelEncoder().fit_transform)\n",
    "x_test.loc[:, ['주구매상품', '주구매지점']] = x_test.loc[:, ['주구매상품', '주구매지점']].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# 이제 float형태 데이터들의 스케일을 맞춰주자.\n",
    "# 스케일변환은 MinMaxScaler를 사용하도록 하겠다.\n",
    "\n",
    "minMaxScaler_train = MinMaxScaler()\n",
    "minMaxScaler_test = MinMaxScaler()\n",
    "\n",
    "minMaxScaler_train.fit(x_train.iloc[:, [0, 3, 4, 5, 6, 7]])\n",
    "minMaxScaler_test.fit(x_test.iloc[:, [0, 3, 4, 5, 6, 7]])\n",
    "\n",
    "x_train.iloc[:, [0, 3, 4, 5, 6, 7]] = minMaxScaler_train.transform(x_train.iloc[:, [0, 3, 4, 5, 6, 7]])\n",
    "x_test.iloc[:, [0, 3, 4, 5, 6, 7]] = minMaxScaler_test.transform(x_test.iloc[:, [0, 3, 4, 5, 6, 7]])\n",
    "\n",
    "# 주구매상품과 주구매지점의 value 종류의 개수를 확인해보자.\n",
    "\n",
    "len(x_train['주구매상품'].value_counts()) # 42개\n",
    "len(x_train['주구매지점'].value_counts()) # 24개\n",
    "\n",
    "# 데이터의 개수에 비해 주구매상품과 주구매지점이 많으므로 해당 데이터의 차원을 줄여야 한다.\n",
    "# 클러스터링을 활용해서 해당 데이터의 차원을 줄여보자\n",
    "\n",
    "km_train_pd = KMeans(n_clusters = 5)\n",
    "km_train_lo = KMeans(n_clusters = 3)\n",
    "\n",
    "km_test_pd = KMeans(n_clusters = 5)\n",
    "km_test_lo = KMeans(n_clusters = 3)\n",
    "\n",
    "km_train_pd.fit(x_train.iloc[:, [0, 1, 3, 4, 5, 6, 7]])\n",
    "km_test_pd.fit(x_test.iloc[:, [0, 1, 3, 4, 5, 6, 7]])\n",
    "\n",
    "x_train['pd'] = km_train_pd.labels_\n",
    "x_test['pd'] = km_test_pd.labels_\n",
    "\n",
    "km_train_lo.fit(x_train.iloc[:, [0, 2, 3, 4, 5, 6, 7]])\n",
    "km_test_lo.fit(x_test.iloc[:, [0, 2, 3, 4, 5, 6, 7]])\n",
    "\n",
    "x_train['lo'] = km_train_lo.labels_\n",
    "x_test['lo'] = km_test_lo.labels_\n",
    "\n",
    "# 주구매상품과 주구매지점 drop\n",
    "x_train = x_train.drop(['주구매상품', '주구매지점'], axis = 1)\n",
    "x_test = x_test.drop(['주구매상품', '주구매지점'], axis = 1)\n",
    "\n",
    "# 이제 데이터셋을 다 만들었으므로 xgboost를 이용해 예측\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_estimator = 400, max_depth = 5, learning_rate = 0.1)\n",
    "xgb_model.fit(x_train, y_train.iloc[:, 1])\n",
    "\n",
    "predict_test = xgb_model.predict_proba(x_test)\n",
    "res = pd.DataFrame(predict_test)\n",
    "\n",
    "res_man = res.iloc[:, 1]\n",
    "\n",
    "res_total = pd.concat([x_test_custID, res_man], axis = 1)\n",
    "\n",
    "print(res_total.head())\n",
    "\n",
    "res_total.to_csv('dfklafjdff/100000.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "# print(x_train.head())\n",
    "# print(x_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e368992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x_train = pd.read_csv('data/X_train.csv')\n",
    "x_test = pd.read_csv('data/X_test.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "\n",
    "train_custID = x_train.loc[:, 'cust_id']\n",
    "test_custID = x_test.loc[:, 'cust_id']\n",
    "\n",
    "x_train = x_train.drop(['cust_id'], axis = 1)\n",
    "x_test = x_test.drop(['cust_id'], axis = 1)\n",
    "\n",
    "print(x_train['환불금액'].isnull().sum())\n",
    "print(x_test['환불금액'].isnull().sum())\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp_train = SimpleImputer(strategy = 'constant')\n",
    "imp_test = SimpleImputer(strategy = 'constant')\n",
    "\n",
    "imp_train.fit(x_train.loc[:, ['환불금액']])\n",
    "imp_test.fit(x_test.loc[:, ['환불금액']])\n",
    "\n",
    "x_train.loc[:, ['환불금액']] = imp_train.transform(x_train.loc[:, ['환불금액']])\n",
    "x_test.loc[:, ['환불금액']] = imp_test.transform(x_test.loc[:, ['환불금액']])\n",
    "\n",
    "x_train['최종구매액'] = x_train['총구매액'] - x_train['환불금액']\n",
    "x_test['최종구매액'] = x_test['총구매액'] - x_test['환불금액']\n",
    "\n",
    "x_train = x_train.drop(['총구매액', '환불금액'], axis = 1)\n",
    "x_test = x_test.drop(['총구매액', '환불금액'], axis = 1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mm_train = MinMaxScaler()\n",
    "mm_test = MinMaxScaler()\n",
    "\n",
    "mm_train.fit(x_train.iloc[:, [0, 3, 4, 5, 6, 7]])\n",
    "mm_test.fit(x_test.iloc[:, [0, 3, 4, 5, 6, 7]])\n",
    "\n",
    "x_train.iloc[:, [0, 3, 4, 5, 6, 7]] = mm_train.transform(x_train.iloc[:, [0, 3, 4, 5, 6, 7]])\n",
    "x_test.iloc[:, [0, 3, 4, 5, 6, 7]] = mm_test.transform(x_test.iloc[:, [0, 3, 4, 5, 6, 7]])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "x_train.loc[:, ['주구매상품', '주구매지점']] = x_train.loc[:, ['주구매상품', '주구매지점']].apply(LabelEncoder().fit_transform)\n",
    "x_test.loc[:, ['주구매상품', '주구매지점']] = x_test.loc[:, ['주구매상품', '주구매지점']].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "print(len(x_train['주구매상품'].value_counts()))\n",
    "print(len(x_train['주구매지점'].value_counts()))\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "KM_pd_train = KMeans(n_clusters = 5)\n",
    "KM_pd_test = KMeans(n_clusters = 5)\n",
    "\n",
    "KM_lo_train = KMeans(n_clusters = 3)\n",
    "KM_lo_test = KMeans(n_clusters = 3)\n",
    "\n",
    "KM_pd_train.fit(x_train.iloc[:, [0, 1, 3, 4, 5, 6, 7]])\n",
    "KM_lo_train.fit(x_train.iloc[:, [0, 2, 3, 4, 5, 6, 7]])\n",
    "\n",
    "KM_pd_test.fit(x_test.iloc[:, [0, 1, 3, 4, 5, 6, 7]])\n",
    "KM_lo_test.fit(x_test.iloc[:, [0, 2, 3, 4, 5, 6, 7]])\n",
    "\n",
    "x_train['pd'] = KM_pd_train.labels_\n",
    "x_train['lo'] = KM_lo_train.labels_\n",
    "\n",
    "x_test['pd'] = KM_pd_test.labels_\n",
    "x_test['lo'] = KM_lo_test.labels_\n",
    "\n",
    "x_train = x_train.drop(['주구매상품', '주구매지점'], axis = 1)\n",
    "x_test = x_test.drop(['주구매상품', '주구매지점'], axis = 1)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5),\n",
    "\tn_estimators = 200, learning_rate = 0.5)\n",
    "\n",
    "ada_model.fit(x_train, y_train.iloc[:, 1])\n",
    "res = ada_model.predict_proba(x_test)\n",
    "res = pd.DataFrame(res)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_data = pd.DataFrame(ada_model.predict_proba(x_train))\n",
    "roc_score = roc_auc_score(y_train.iloc[:, 1], roc_data.iloc[:, 1])\n",
    "\n",
    "print(roc_score)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2326c34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08409d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
